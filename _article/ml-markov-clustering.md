---
layout: post
title: 'Markov Clustering'
date: 2022-05-08 00:00:00-0400
description: 'Expansion and Inflation'
tags: Stats, Cluster
category: ML
subcategory : Clustering

---


# 1. Abstract 
<!-- 
ÎßéÏùÄ ÏñëÏùò Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÏùÑ Îïå, Ïù¥Î•º Ìï¥ÏÑùÌïòÎäî Ï¢ãÏùÄ Î∞©Î≤ïÏùÄ Ïú†ÏÇ¨Ìïú Îç∞Ïù¥ÌÑ∞Îì§ÏùÑ Í∑∏Î£πÌïëÌïòÏó¨ ÎßåÎì§Ïñ¥ÏßÑ ÌÅ¥Îü¨Ïä§ÌÑ∞Îì§ÏùÑ Ìï¥ÏÑùÌïòÎäî Í≤ÉÏù¥Îã§. 
ÌÅ¥Îü¨Ïä§ÌÑ∞Î•º ÎßåÎìúÎäî Í∏∞Ï§ÄÏùÄ Ïó¨Îü¨ Í∞ÄÏßÄÍ∞Ä ÏûàÎäîÎç∞, Í∑∏ Ï§ëÏóêÏÑú Markov Decision ProcessÏóêÏÑú ÏòÅÍ∞êÏùÑ Î∞õÏùÄ Markov ClusterÎ•º ÏÜåÍ∞úÌïúÎã§. 
Îç∞Ïù¥ÌÑ∞ Ìè¨Ïù∏Ìä∏Îì§ÏùÑ MarkovÏ†ÅÏúºÎ°ú ÏÉùÍ∞ÅÌïòÎäî Î∞©Î≤ïÏùÄ Îã§ÏùåÍ≥º Í∞ôÎã§.
Î®ºÏ†Ä Îç∞Ïù¥ÌÑ∞ Ï†êÎì§ÏùÑ ÎÖ∏Ìä∏ÎùºÍ≥† Í∞ÄÏ†ïÌïòÍ≥†, Ï†êÎì§Ïùò Í∏∏Ïù¥Î•º EdgeÎùºÍ≥† ÌïòÏûê. 
Í∑∏Îü¨Î©¥ Î™®Îì† ÎÖ∏ÎìúÎì§Ïù¥ Ïó∞Í≤∞Îêú Complete Graph Í∞Ä ÎßåÎì§Ïñ¥ÏßÄÍ≥†, Ïù¥ Í∑∏ÎûòÌîÑÏóêÏÑú Ïó£ÏßÄÎì§ÏùÑ ÏóÜÏï†Îäî Î∞©Ìñ•ÏúºÎ°ú 
ÌÅ¥Îü¨Ïä§ÌÑ∞Î•º ÎßåÎì§ Ïàò ÏûàÎã§. 
ÌïòÎÇòÏùò ÎÖ∏ÎìúÏóêÏÑú Ï∂úÎ∞úÌïòÏó¨ Ï£ºÎ≥ÄÏùÑ ÎèåÏïÑÎã§ÎÖîÏùÑ Îïå Î∞©Î¨∏ÌïòÎäî Ï†êÎì§Ïù¥ ÌÅ¥Îü¨Ïä§ÌÑ∞Ïùò ÏõêÏÜåÍ∞Ä ÎêòÎäî Í≤ÉÏù¥Îã§. 

Markov Decision ProcessÏóêÏÑú Stationary Ìïú Í≤ΩÏö∞, ÌïòÎÇòÏùò StateÏóêÏÑú ÎåÄÌïú Î∞©Î¨∏ ÌôïÎ•†ÏùÄ Ïù¥ÏõÉÎì§Ïùò ÌôïÎ•†Î°úÎ∂ÄÌÑ∞ ÏïàÏ†ïÏ†ÅÏúºÎ°ú Íµ¨Ìï¥ÏßÑÎã§.
Ìïú Í∞ÄÏßÄ Î¨∏Ï†úÏ†êÏùÄ ÌôïÎ•†Í∞íÏù¥ ÎåÄÎ∂ÄÎ∂Ñ 0Ïù¥ ÏïÑÎãàÍ≥† ÏûëÏùÄ Í∞íÏùÑ Í∞ÄÏßÄÍ≥† ÏûàÎã§Îäî Í≤ÉÏù¥Îã§. Ïù¥ Í≤ΩÏö∞, Î©ÄÎ¶¨ ÏûàÎäî ÎÖ∏ÎìúÏóê ÎåÄÌïú EdgeÎ•º Ï§ÑÏó¨Ïïº ÌïúÎã§. 
Markov Cluster ÏóêÏÑúÎäî Î∞òÎ≥µÏ†ÅÏúºÎ°ú Ïó£ÏßÄÏùò Ïó∞Í≤∞ÏÑ±ÏùÑ Sparse ÌïòÍ≤å ÎßåÎì¨ÏúºÎ°úÏç® ÌÅ¥Îü¨Ïä§ÌÑ∞Î•º Í∞ïÏ†úÌïúÎã§. 
 -->

When large number of samples are distributed, one of the best ways to understand the structure is clustering. 
Several cluster methods have been proposed and Markov Clustering is one method motivated by Markov Decision Process (MDP). 
The perspectives of MDP in clustering is as follows. 

* üçÄ Consider the data points as **states** and edge length as **the next state transition probability**.
* üçÄ The full data could be understood as a **complete graph** and clusters could be formed by **removing edges** so that disjoint subgraphs. 
* üçÄ Edge lengths become **sparse** by the power of the transition matrix. 

In MDP, state transition could be non-zero for other states. As we want to form a clusters, we should make the transitions as sparse. 
Markov Clustering handles this issue by `Inflation` (element ) so that low signals become zero and high signals become higher. 


# 2. Motivation 
<!-- 
ÌÅ¥Îü¨Ïä§ÌÑ∞Ïùò ÏÉòÎì§ÏùÄ Markov Decision ProcessÏùò StateÎì§Ïù¥Í≥† Ïù¥ÏõÉÎì§ÏùÄ Transition(Random Walk)ÏúºÎ°úÎ∂ÄÌÑ∞ Î∞©Î¨∏ÌïòÎäî Ï†êÎì§Ïù¥Îã§. MatrixÏóê ÎåÄÌïú ÏßÄÏàòÏäπÏúºÎ°ú Ïó∞Í≤∞ÏÑ±ÏùÑ Sparse ÌïòÍ≤å ÎßåÎì§Î©¥ÏÑú Í∑∏ÎûòÌîÑÏùò Ïó£ÏßÄÎ•º ÏóÜÏï§Îã§. 
 -->
 The elements in a cluster is states in Markov Decision Process and neighbors are possible next states. In Markov Cluster, edge connects become sparse by the power of matrix. 
The constructed clusters are formed by the edge distances. 

# 3. Method

Assume that we have a complete graph $G$ whose edge is the distance between two vertices. 
The markov clustering is an iterative algorithm which propagates signals to neighborhoods and makes signals sparse.  
There are two operations `Expansion`  and `Inflation`. 

1. üöÄ **Expansion** : propagate signals to neighbors with edges.  
2. üöÄ **Inflation** : make signals sparse by making large signal larger and small signal smaller. 



<hr/>
<center>
<h2 style='border:5px outset; color:blue; text-align:center; width:200px; padding:2px;'>
Expansion 
</h2>
</center>



Let $M_0$ be a $n\times n$ matrix whose element is the distance to another node at time $t$. The `expansion` operation propagate signals to neighborhoods with matrix multiplication.   

$$
M_{t+1} \leftarrow (M_{t})^p
$$

Here $p$ is a hyperparameter which controls the transition length of the signal. That is, if $p=2$, only direct neighborhoods are communicated.  

<hr/>

<center>
<h2 style='border:5px outset; color:orange; text-align:center; width:200px; padding:2px;'>
Inflation
</h2>
</center>


Given a matrix $M \in \mathbb{R}^{k\times l}, M \ge 0$ and a real nonnegative number $r$. 
Inflation operation is defined by 

$$
M_{t+1, ab} = (M_{t, ab})^r / \sum_{k=1}^k (M_{t, kb})^r
$$

where $a,b$ is the edge distance from $a$ to $b$ and $t$ is the iteration number. 



<center>
<div class="row mt-3">
        <div class="col-sm mt-3 mt-md-0">
            {% include figure.html path="assets/img/exp14/animation_cluster.gif" class="img-fluid rounded z-depth-1" zoomable= true %}
        </div>
</div>
</center>


#### Code Implementation 


```python
def expansion(matrix, p):
    assert p>=1
    from numpy.linalg import matrix_power
    return matrix_power(matrix, p)  # information communication. 

def inflation(matrix, r):
    assert r > 0 
    inflated_matrix = matrix**r
    normalized = normalize_column(inflated_matrix)
    return normalized

def normalize_column(matrix):
    assert matrix.ndim == 2
    normalized = matrix / matrix.sum(axis=0)
    return normalized
```






# 4. Discussions 

Strengths

* If we can view the data points as random walkable, Markov Clustering is a suitable way of cluster them 
* Easy intuition and implementation 
* The order $p$ is based on information communication  



Weaknesses

* Matrix multiplication requires $\mathcal{O}(N^2)$ complexity. 
* Even though iteration makes edges sparse, we need threshold to cut them.
* The order $p$ is a hyperparameter and we should tune them. 

# 5. Related Work 


* Unlike Markov Transition, <tag class="text-box" style='color:red;'>Spectral Clustering</tag>   is based on removing edges which have little affect on the graph structure. 
*  <div><tag class="text-box" style='color:red;'>KNN</tag> or <tag class="text-box" style='color:red;'>K-means</tag>  also consider the neighborhoods, but Markov Clustering assumes graph structure. </div>



#  References 

* [Clustering on Graphs: The Markov Cluster Algorithm (MCL)](https://sites.cs.ucsb.edu/~xyan/classes/CS595D-2009winter/MCL_Presentation2.pdf)
* [Markov Clustering Demo](https://micans.org/mcl/ani/mcl-animation.html)
* [MCL -  a cluster algorithm for graphs](https://micans.org/mcl/)
* Protein sequences clustering of herpes virus by using Tribe Markov clustering (Tribe-MCL)
* [Performance Criteria for Graph Clustering and Markov Cluster Experiments]()



<hr/>


## Full Markov Clustering Code 

```python 
def markov_clustering(matrix, expansion_p, inflation_r, max_iteration=300, save_progress=False):
    iteration = 0 
    matrix = normalize_column(matrix)  # Transition 
    progress = []

    while True:
        if iteration >=max_iteration:
            break 
        matrix_1 = expansion(matrix, expansion_p)  # step 1 expansion (information communication)
        matrix_2 = inflation(matrix_1,inflation_r) # step 2 inflation (sparse)
        matrix = matrix_2
        iteration += 1        

    indices = matrix.argmax(axis=0)
    output = {
        "indices" : indices, 
        "clusters" : get_cluster_index(matrix),
        "matrix" : matrix,
        "iteration" : iteration,
        "progress" : progress
    }
    return output
```


