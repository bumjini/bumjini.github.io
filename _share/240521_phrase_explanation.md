---
layout: distill
authors: 
    - name: Bumjin Park
      affiliations:
        name: KAIST
bibliography: all.bib
date: 2024-05-21
giscus_comments: true
title: 'Safety Phase Explanation in Large Language Models'
description: '안전장치로 학습된 모델의 phase transition에 대한 체계적 연구. ' 
---


## Collection of Papers 

* **Safety finetuning + deceiving** 
    * Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training
    * Simple probes can catch sleeper agents

* **Safety finetuning**
    * Training a helpful and harmless assistant with reinforcement learning from human feedback
    * Training language models to follow instructions with human feedback

* **Jail-break** 
    * Defending chatgpt against jailbreak attack via self-reminders
    * Many-shot Jailbreaking

* **Safety** 
    * Towards understanding sycophancy in language models

* **Interpretability (feature)**
    * Towards Monosemanticity: Decomposing Language Models With Dictionary Learning
    * Mapping the Mind of a Large Language Model


---



## Abstract 




## Introduction 



## Related Work



## Method


## Experiments 


## Results 


## Conclusion



