---
layout: share-distill
title: '[연구 5] 8개의 ML 모델과  물성모델링'
date: 2023-10-23
giscus_comments : true
description: "1,2차 데이터 동시 취합 및 XGBoost 추가 적용. 물성 모델링에 대해서 적은 코드 개수를 적용하여 예측 할 수 있는 방법을 연구한다."
authors: 
    - name: Bumjin Park
      affiliations:
        name: KAIST

img: https://drive.google.com/uc?export=view&id=1LhC7shBOObQGoLo2ftxgK8Q-Wjajq-vi
---

## 1. Report Info   

<div class="spanbox" markdown="1" style="width:40rem;background-color:#FFFDFD;">
1. 👨🏻‍💻 **Code Release**:  Tag [v23.10.23.1](https://github.com/fxnnxc/kolmar/tree/v23.10.23.1)
2. 📂 **Raw Data** :  (3.1, `raw_data:receipt_3`)   <br> # 3.1 은 1차 및 2처 처방을 합치고 코드별로 합산한 데이터
3. 🗂️ **Datasets** :  (2, `ds:receipt_3_ml`)  
4. 👾 **Models** :  1~8 까지 8개의 ML 모델 
5. 🦄 **Trainers** : (1, `sklearn_regressor`)
6. 📌 **Related Notebooks** 
  * [receipt_3 target dist.ipynb](https://github.com/fxnnxc/kolmar/blob/v23.10.23.2/labs/receipt_3_eda/dataset.ipynb)
  * [plot_rmse.ipynb](https://github.com/fxnnxc/kolmar/blob/v23.10.23.2/labs/receipt_3_rmse/plot_rmse.ipynb)
  * [pdp.ipynb](https://github.com/fxnnxc/kolmar/blob/v23.10.23.2/labs/receipt_3_rmse/pdp.ipynb)
</div>


저번 미팅에서 의논한대로, 현재는 **데이터에 적합한 모델을 찾는 것보다** 머신러닝 모델에 대한 이해 및 데이터 구축에 연구 시간을 보내고 있다. 이번 주 보고에서는 ML 모델에 대한 사용을 마무리하고, 프로젝트에 적합한 **모델 입력 디자인**에 대해서 논한다. 레포트 구성은 다음과 같다. 

1. 3차 처방데이터 (1차와 2차의 총합)
2. 3차 처방 예측값 상관관계 표 
3. 8개의 머신러닝 모델 
4. 8개 모델에 대한 PDP
5. !프로젝트 연구를 위한 본질적인 연구 주제 📌
6. 물성 모델링 📌
7. 결론

## 1. 3차 처방 데이터 


1차 처방데이터와 2차 처방데이터를 취합한 데이터셋 구축하였다. 데이터셋에 따른 모델 학습은 향후 다시 구분하여 학습을 진행할 수 있기에 특별한 이유가 없을 때까지는 증가된 데이터셋으로 학습 및 분석을 진행한다. 3차 처방데이터는 1,2차 데이터를 합친 것으로 다음과 같으 처리를 통하여 총 `1745개`의 입력데이터가 존재하며, 코드 개수는 `5485개`이다. 

<d-code language='python'>
[INFO] dropping NaN targets...
[INFO] sum by duplicated lab numbers for targets...
[INFO] modified number of targets by dropping NaN and duplication: 1771 --> 1745
[INFO] fill one-hot code for all targets in the order of unique_formulas in data_raw excluding codes if code-idx < 5485
100%|██████████| 1745/1745 [00:18<00:00, 92.10it/s]
--------------------------------------------------
[INFO] 🗂️ Dataset: Receipt3DatasetBaseML X:(1745, 5485)  Y:(1745,)

</d-code>

3차 데이터의 경우 1차 및 2차 데이터를 결합한 데이터셋이므로, 
예측값에 대한 분포는 두개의 분포를 결합한 것과 동일하다.  
<center>
<div class="spanbox" markdown="1" style="width:40rem;background-color:#FFFDFD;margin-left:0rem;">
### 1차/2차 점도 예측 목표 
<img src="https://drive.google.com/uc?export=view&id=1759r2Afe8HKChHH_oNoePBw9akxC8RNq" style='width:39%'>
<img src="https://drive.google.com/uc?export=view&id=16-ZXy2tI6s72_agj7pzy4PTM7IrcB4hd" style='width:39%'>
### 3차 처방 데이터의 점도값 분포는 다음과 같다.
<img src="https://drive.google.com/uc?export=view&id=1WCDCzgN8LAad5xYpP7g4D0ZMd4k01QbF" style='width:80%'>
</div>
</center>

## 2. 3차 처방 예측값 상관관계 표 

각 코드에 대해서 단순선형모델 및 상관관계를 구해보면 다음과 같다.

<img src="https://drive.google.com/uc?export=view&id=1h50lUJTqPyeaMWt2v8OiX2uJpU7C3IRU" style='width:80%'>

* 전체 데이터는 [correlation.xlsx](https://docs.google.com/spreadsheets/d/1PbeJslr2Rv1o-5FHJ0SMB091RzlnfUle/edit?usp=sharing&ouid=112523016502479227051&rtpof=true&sd=true) (구글드라이브 보안접근)에서 확인할 수 있다.

## 3. 8개의 머신러닝 모델 

머신러닝에 사용되는 모델은 크게 3 종류로 구분된다. 

1. 파라미터 회귀형태  : 입력값에 계수를 곱해서 예측이 진행되는 형태이다. 
2. 의사결정나무 형태  : 분기를 기준으로 나눠서 예측을 진행한다. 
3. Non-parametric 데이터 기반 : 학습데이터와 비교를 통해서 예측을 진행한다. 

학습에 사용되는 모델은 다음과 같다. 

1. 파라미터 회귀형태  : `lasso_linear`, `ridge_linear`, `linear`, `SVR`, `bayes_ridge_linear`
2. 의사결정나무 형태  : `random forest`, `lightGBM`
3. Non-parametric 데이터 기반 : `KNeighborRegressor`

학습에서는 학습용과 테스트용을 나눠서 진행한다. 학습데이터의 일부는 검증용 데이터로 다시 사용된다. 
괄호는 (입력 샘플 수, 입력 변수 수), (출력 샘플 수) 를 나타낸다. 

* **학습데이터** (1221, 5485), (1221,) 
* **테스트데이터** (524, 5485), (524,)

1/10000의 값에 대해서 학습 모델을 돌리면 다음과 같은 결과를 얻는다. 

* x축 : 학습에 사용된 코드 개수
* y축 : Root Mean Squared Error 평균 


<div class="spanbox" markdown="1" style="width:60rem;background-color:#FFFDFD;margin-left:-5rem;">
### RMSE
<center>
<img src="https://drive.google.com/uc?export=view&id=1LhC7shBOObQGoLo2ftxgK8Q-Wjajq-vi" style='width:100%'>
</center>

1. 선형모델은 학습과 테스트 데이터의 결과가 모두 에러가 높게 나왔다. 따라서 부적합하다. 
2. LightGBM 은 학습 및 테스트에 대해서 모두 최고의 성능을 보여준다. 
3. KNR 이 학습에 대해서 성능이 높은 것은 실제 학습값을 반환하기 때문이다. 대신, 테스트에 대해서도 학습데이터의 Y를 내보낸다. 따라서, Test에서 KNR 보다 성능이 안 좋은 모델들은 모두 `학습 데이터로 맵핑`한 예측보다 안 좋은 모델로 판단하면 된다. 
4. RF의 경우, 학습데이터에 대해서는 좀더 에러가 LightGBM보다 높은데, 이는 LightGBM 이 더욱 세분하게 예측값을 쪼개기 때문이다. 

</div>



## 4. 8개 모델에 대한 PDP

PDP 는 기존 학습데이터에서 코드를 정하고 0~100까지 강제로 변화시킨 데이터를 모델에 넣어 평균적인 코드의 예측값을 보는 방법이다. 

* x-축: 특정 코드에 대한 값  
* y-축: 평균 점도 (3차 처방 데이터)

<div class="spanbox" markdown="1" style="width:60rem;background-color:#FFFDFD;margin-left:-5rem;">
### PDP

PDP에 대한 해석은 이번 보고서에서는 분석하지 않는다. 왜냐하면 입력에 대한 적합한 모델링 이후 다시 제대로 모델을 학습하고 진행하는 게 맞기 때문이다. 
<center>
<img src="https://drive.google.com/uc?export=view&id=1v-rD7f-pfwN8meUaM2lwZXt_Z740vLR7" style='width:100%'>
<img src="https://drive.google.com/uc?export=view&id=1aDLc5Cdh6XX5m5OzFFaGgzenG1onFKWj" style='width:100%'>
</center>
</div>


## 5. !프로젝트 연구를 위한 본질적인 연구 주제


프로젝트를 진행하면서 점도 예측에 대해서 어려운 점은 코드 개수가 5000개가 넘는데, 데이터의 샘플은 1700여개라는 점이다. 이는 학습데이터가 아주 적은 것을 의미하며, 학습 모델에 몇 가지 문제점을 지니고 있다. 

#### (코드 개수가 너무 많은 것에 대한 문제점)
1. 많이 사용된 코드에 적합하게 학습된다. <br> 적은 코드는 영향을 거의 미치지 못한다. (대부분 값이 0으로 들어가기 떄문에)
2. 적은 샘플을 가지는 코드가 큰 weight을 지닐 수 있다. 이 경우, 일반화가 되었다고 판단 오류를 내릴 가능성이 높다. 

따라서 적은 샘플을 가지는 코드는 학습이 제대로 진행되지 못했을 가능성이 높다. 그렇다면, 현재 상황에서 필요한 것은 단순히 코드로부터 점도를 예측하는 것을 넘어서, 
적은 샘플을 지니는 코드로부터 학습하는 방법이다. 머신러닝/딥러닝 학습 전에 먼저 목표로 하는 점은 다음과 같다. 


#### (개선된 연구 주제)
1. **충분한 실험 개수를 지니는 코드에 대한 점도 영향력 측정.**
2. **적은 실험 개수를 지니는 코드에 대해서 예측 방법 제안.** 




## 6. 물성 모델링 

물과 꿀을 섞는 것을 예로 들어보면, 물과 꿀은 서로 점도를 지니고 있다. 두 물질은 서로 다른 점도 $\rho_1$ $\rho_2$ 를 지니고 있으며, 화학적인 성질 $\psi_1, \psi_2$ 를 가지고 있다. 
두 개를 $x$ 와 $1-x$ 만큼 섞는 경우 물보다는 진하고 꿀보다는 연한 상태가 되기에,  점도 $\rho$ 는  $\[ \rho_1, \rho_2 \]$ 에 놓이게 됨이 자명한데, 만일 화학적인 성질로부터 점도가 유도될 수 있다면, 혼합물의 점도 $\rho$ 는 적당한 함수 $f$에 의해서 결정난다. 

$$
\begin{equation}
\rho = f(\psi_1, \psi_2, x, 1-x)
\end{equation}
$$

딥러닝의 목적은 근사함수 $f_\theta$ 를 찾는 것으로, 적당한 모델 파라미터 $\theta$ 로부터 Loss를 최소화는 파라미터를 찾는다. 

$$
\begin{equation}
\theta^\star = \arg \min_\theta \mathcal{L}(f_\theta(x, x-1), f(\psi_1, \psi_2, x, 1-x))
\end{equation}
$$

레올로지로부터 얻어지는 값 $y$는 $f(\psi_1, \psi_2, x, 1-x)$ 를 대체하므로, 실험적으로 얻어진 값 $y$ 로 $f$ 를 대체하여 $\theta$를 찾는다. 

$$
\begin{equation}
\theta^\star = \arg \min_\theta \mathcal{L}(f_\theta(x, x-1), y)
\end{equation}
$$

적은 개수의 코드에 대해서 **수식 1** 과 같이 화학적인 성질 및 섞는 비율에 의해서 점도가 결정난다면, **비슷한 화학적 성질 및 양을 지니는 물질에 대해서는 $\rho$ 값이 유사하게** 나타날 것이다. 
**이는 $f$ 함수가 화학적성질 및 섞는 비율에 대해서 Smooth**한 성질이 있다고 가정하는 경우에 가능하다. 즉, 화학적 변화의 차이에 따라서 예측의 차이에 영향을 미친다는 가정이다. 이 가정은 물성을 결정하는 적합한 화학적 성질과 물성의 관계가 존재함을 나타내며, 해당 화학적 성질이 비슷한 두 물질은 서로 교체되어도 $\rho$ 값이 크게 변하지 않을 것이다. 

따라서, **5485개의 코드에 대해서 점도를 결정하는 유사한 성질을 유도해낼 수 있다면**, 비록 샘플 수가 적을지라도 유사한 코드 중 가장 많은 샘플로 대체되면 문제가 해결된다. 
예로, 코드 개수를 100개로 줄일 수 있다면, 변수와 데이터의 비율은 (5485:1745) 에서 (100:1745)로 줄어든다. 이를 통해 더욱 정확한 머신러닝 모델을 학습시킬 수 있다. 

(만일 화학적인 특성 없이 단순하게 비율대로 결정이 난다면, $\rho = \rho_1 x_1 + \rho_2 x_2$ 식으로 쓸 수 있을 것이다. 이 경우, 각 코드별로 점도를 예측하고, 단순하게 곱해서 더하면 점도가 예측되어야 한다. 각 물질별로 단 한번의 실험으로 점도를 결정할 필요가 있으므로 코드 개수만큼 실험을 돌려야 한다. 결국 코드 수만큼 필요하다면, 샘플이 코드 개수보다 적은 경우는 Least Square에서 Rank가 더 작은 상태와 동일하다. )

### 3개 이상을 섞는 경우 

위의 수식에서는 2개의 코드에 대해서 섞는 것을 나타냈는데, 여기서는 3개의 코드에 대해서 섞는 경우를 분석한다. 
코드 개수 $K$ 를 섞는 경우, 각 물질의 특성을 $\psi_k$, 양을 $x_k$ 라고 하면, 해당 조합을 섞었을 때 결정되는 점도는 다음과 같은 식 $f$로 유도된다고 가정한다. 

$$
\begin{equation}
\rho = f(\psi_1, \psi_2, \cdots, \psi_K, x_1, x_2, \cdots, x_{K-1}  )
\end{equation}
$$

화학적 특성으로 물성을 결정할 수 있다는 가정에서는 샘플이 적은 코드 $j$ 에 대해서 화학적인 특성이 유사하다면, 코드 $j$ 는 가장 비슷한 다른 코드 $\hat{k}$ 로 맵핑될 수 있다.  

$$
\begin{equation}
\hat{k} = \arg \min_{k\in [K_j]} d(\psi_k, \psi_j)
\end{equation}
$$

코드 인덱스 $k$ 가 데이터 수로 정렬되어 있다고 가정할 때, $K_j$ 는 코드 $j$ 보다 샘플수가 충분히 많은 코드의 인덱스이다. 
이로 인해서, $j$ 코드의 특성 $\psi_j$ 는 $\psi_{k'}$으로 치환된다. 치환되면 $j$ 의 함량은 $\hat{k}$의 함량으로 추가되며, 머신러닝 모델링에서 $\rho$ 를 결정하는 파라미터 $j$ 는 사라지게 된다. 
이러한 코드 치환은 $d(\psi_k, \psi_j)$ 에서 발생하는 에러가 작을수록 바람직하며, 적절히 요구되는 특성이 유사한 코드가 있다면, $d(\cdot, \cdot)$ 은 작아진다. 

이 수식적 분석을 통해서 최종적으로 모델링 해야 하는 것은 **점도 예측에 유의미한 $\psi$ 표현을 찾는 것**이다. 찾아낸 표현으로부터 코드 치환 알고리즘을 최적화하는 경우, 
물질 결합시 화학적 특성으로 물성이 결정난다는 **수식1**의 점도 결정 함수가 옳다는 가정하에서 치환을 통한 방식은 적은 물성 예측 에러를 지니게 된다. 

--- 

### Direct Solution of 5 using distribution

(이 부분을 정확하게 수식으로 모델링 하려면 고생이 좀 필요할 것 같다.. 그래서 다음에 필요하면 연구할 계획이다.)

물질의 성질 $\psi$ 값은 점도를 결정지어야 하기 때문에 적절한 $\psi$ 를 모델링 하는 것은 쉽지 않다. 대신 수식5 에서 구하는 distance $d(\psi_k, \psi_j)$를 확률적인 차이로 치환할 수 있다. 
두 개의 코드에 대해서 점도의 확률분포가 얼마나 유사한지, 다른지를 판단한다면, 화학적인 성질 $\psi$를 구하지 않고 분포의 차이로부터 $k$ 를 구하는 방식이다. 

$$
\arg \min_{k \in [K_j]} d(\psi_j, \psi_k) = \arg \min_{k \in [K_j]} d(p(Y|X_j;\hat{X}), p(Y|X_k;\hat{X})) 
$$

즉, 점도의 예측값이 유사하다면, 코드는 다른 코드로 치환될 수 있는 것이다. 예를 들어서, A 라는 물질로 몇 번의 실험으로 점도 예측을 하는 경우, 비슷한 함량을 섞었을 때, 예측 값이 비슷한 다른 코드가 있다면 치환될 수 있다는 가정이다. (To be continued...)


## 7. 결론

머신러닝 / 딥러닝 모델은 주어진 입력-출력에 대해서 학습에 장점이 있다. 따라서, 모델 학습으로 예측을 진행하는 것은 가능한 사항이다. 
다만, 현재 프로젝트에서는 코드의 종류가 무수히 많으며, 적은 데이터로 유의미한 모델을 만들 필요가 있다. 따라서, 단순히 머신러닝/딥러닝을 적용하여 사용하는 것보다
적은 수의 실험으로 물성을 예측하는 방식에 대한 논의가 우선적으로 필요하다. 이후 코드 수의 문제가 일부 해결되면, 머신러닝/딥러닝으로 학습 및 예측을 진행하고, 모델의 결과를 해석하여 유의미한 인사이트를 얻을 수 있을 것으로 기대된다. 
