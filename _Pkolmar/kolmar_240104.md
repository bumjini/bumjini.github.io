---
layout: share-distill
title: '[연구 13] 최종 목표 설정'
date: 2024-01-04
giscus_comments : true
description: "2월달 연구 결론을 위한 최종 목표 설정"
authors: 
    - name: Bumjin Park
      affiliations:
        name: KAIST

img: https://drive.google.com/uc?export=view&id=1UIxosn1uLCMnJk7rviqSku5o0YEJhoCf
---

본 연구에서는 2월 최종 보고를 위한 목표를 설정하고 모델 검증 및 신뢰성 확보를 위해 필요한 연구들을 나열한다. 

## [평가 목표: Quantitative] 
1. 물성 예측의 정확도
2. 원료 표현의 유용성
3. 물성 표현의 유용성

#### 물성 예측 정확도 (물성 예측 모델은 특정 물성에 대해서 잘 예측해야 한다.)
* Ex) 점도 예측의 성능이 높아야 한다.  

#### 원료 표현 유사도 (비슷한 원료는 비슷한 표현을 지녀야 한다.) 
* 원료 표현을 분석하여 어떤 정보를 얻을 수 있는가? 
* 전문가의 유사도를 기반으로 원료 표현을 찾았을 때, 성능이 오르는가?
* 특정 알고리즘을 통해 원료 표현을 찾았을 때, 성능이 오르는가? 
* Ex) MMM002 를 MMM000 의 원료 표현으로 바꾼다. 

#### 물성 표현 유사도 (비슷한 예측 특성은 비슷한 Task 표현을 지닐 것이다.) 
* 학습 결과로 각 물성 표현 벡터는 서로 유사하게 형성되는가?
* 데이터 수가 적은 물성에 대해서 학습 데이터가 많고 유사한 물성에 대한 표현으로 바꿨을 때 예측 성능이 오르는가? 
* Ex) 4pin 과 6pin 은 모두 점도 예측에 사용된다. 점도 예측 벡터는 유사하게 형성되는가? 



## [AI 모델 관련 추가 실험] 
1. Mixer 학습에 방식은 학습 성능을 올리는가? 
2. 원료 개수 감소 : 특정 알고리즘이나 전문가의 견해를 바탕으로 원료 개수를 줄이는 경우, 학습 성능은 얼마나 향상되는가? 
3. 물질의 양을 넣는 방법은 학습 성능에 차이를 보이는가? (amount) 
4. MixturePredictor 하이퍼 파라미터에 대한 테스트 
5. Attention Map은 유의미하게 형성되는가? 분석할 수 있으며, 분석이 유용한가? 
6. 기본 원료 표현은 유의미하게 형성 되는가? 


## [추가적인 궁금증]
1. 현재 구조는 데이터 수가 많아짐에 따라서 학습 성능은 확실히 좋아지는가? 
2. RPM에 대해서 절반씩 떨어지는 경향성을 그대로 보이며 학습되는가? 


## 모델 학습 관련 내용 
* Layer normalization 을 없애야 한다. amount를 곱해주는데, LN은 다시 원상복구 하기 때문이다. 
* amount 를 넣는 방법으로 곱하는 대신에 추가적인 dimension을 주는 방법이 있다. 
* AdamW optimizer를 사용해야 좀더 일반화가 될 것으로 판단된다. 
* base_dim 자체가 작으면, 초기 시작되는 사이즈가 작다. 따라서 원료들의 표현이 좁은 공간에 형성된다. 
* mixer_dim 자체는 커도 상관없다. 해석에는 영향을 미치지 않는다. 

--- 

## Mixer 

믹서의 중요한 목표는 예측하고자 하는 물성에 대한 표현과 원료에 대한 표현을 섞어 예측용 표현을 만드는 것이다. 
입력으로 물성심층표현과 복수 개의 원료심층표현이 주어지며, Mixer 는 self-attention 을 바탕으로 미들을 섞어 물성표현벡터가 필요한 정보를 담고 있도록 설계한다. 

아래 그림에서 pH벡터는 `pH` 예측을 위해 할당된 벡터로 **믹서를 통과하고 나면** 처방 정보를 담고 있도록 설계된다.  

<center>
<img src="https://drive.google.com/uc?export=view&id=1UIxosn1uLCMnJk7rviqSku5o0YEJhoCf" style="width:100%"> 
</center>

### Input Example

입력의 실제값을 보면 다음과 같이 3 가지가 주어진다. 
1. 예측 물성 레이블
2. 원료 코드
3. 원료 함량 

이 중 원료 코드는 batch-size 를 맞추기 위해서 zero padding을 통하여 63개로 설정된다. Mixer에 넣을 때는 예측 물성 레이블과 붙여서 학습 모델에 들어간다. 
<center>
<img src="https://drive.google.com/uc?export=view&id=1F2UMnFWfuSWu0QICl2o91vuZHyXOPnV4" style="width:100%"> 
</center>


## Training Loss 

혼합된 데이터에 대해서 학습 성능은 다음과 같다. 
cut-threshold 는 빈도수 기준으로 1 또는 2 이상의 원료만 포함된 처방으로 학습된 결과를 보여준다. 
학습이 진행됨에 따라서 `training` 과 `evaluation` 성능이 모두 향상되는 것을 볼 수 있으며, cut-threshold 2가 1보다 더 일반화가 잘 되는 것으로 보인다. 
학습 가능성을 확인하기 위해 경향성만 파악하였다.

<center>
<img src="https://drive.google.com/uc?export=view&id=1d2O3uJayLz7ssT3ra1rbmuwQm-mMlMcd" style="width:100%"> 
</center>


## Attention Map 해석
