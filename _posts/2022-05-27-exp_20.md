---
layout: post
title: 'ðŸ—º #20 ViT Class Decision Map by Attention'
date: 2022-06-03 00:00:00
description: Visualize global explanation of vision transformer by attention and gradient.  
tags: XAI, VISION
categories: XAI
---

# 1. Introduction 

Transformer encoder has


# 2. Background 

# 3. Method


<p>
Given decision of the function on the class $f^c(x_i)$, input attribution is computed by $\nabla f^c(x_i) $ The attention score $A_{l,h}(x_i)$ represents the attention score of head $h$ in layer $l$ for instance $x_i$.  First, the scores are normalized to gaurantee  $||\nabla f^c(x_i)||_2 = 1$ and $||A_{l,h}(x_i)||=1$. Then, the similarity of the attentino score and the input attribution is calculated by </p>

$$
S_{l,h}^c(x_i) = \cos{\Big(\nabla f^c(x_i), A_{l,h}(x_i)  \Big)}
$$

Note that it measures the difference between attention map and the input attribution. By computing $S_{h,l}^c(x_i)$ over all heads and layers, 
we obtain the **class attentnion decision vector** 

$$v^c(x_i) = [S_{1,1}^c(x_i), S_{1,2}^c(x_i), \cdots,  S_{L, H-1}^c(x_i), S_{L,H}^c(x_i)]^{\mathrm{T}}$$

These vectors are further represented by T-SNE. 

# 4. Result 

We evaluated our method on the ImageNet 2012 Validation dataset. The dataset has 50000 images with 1000 classes. Therefore, 50 images for each class. We used the SmoothGrad for the input attribution method. 



### 4.1 Input Attribution Comparison

### 4.2 Attention Map 

### T-SNE



# 5. Conclusion 



