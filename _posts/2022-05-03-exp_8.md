---
layout: post
title: 'ðŸ¤– #8 LRP Scores in Training Rosbot Navigation'
date: 2022-05-03 01:53:01
description: This article explains the change of feature importance while training rosbot agent. 
tags: ros, rl, xai
categories: rl
---


### 1. Motivaiton of this expeirment

In recent years, deep learning has achieved state-of-the-art control in many fields, including robotics, medicals, and visions. There are many studies explaining the decision process of the deep neural network. Most of the studies assumed that the model is fully trained. However, there is another branch which describes the dynamics of training itself. As the usage of deep learning increases, it is necessary to explain the change of the decision process while training. In this experiments we demonstrate the scores of Layer-wise relevance propgation (LRP) for robot navigation task. 


### 2. Training 

We used Rosbot simulator in Gazebo and 3 layers `26-32-64-128-10` fully connected model with `relu` activation to train the policy of the model. Our training algorithm is Proximal Policy Optimizer (PPO) which is widely used on-policy method to train a reinforcement leraning agent. Even though PPO can be trained with continuous actions, we used discrete action to clearly distinguish the actions. Our observation space includes the kinematic information of the robot and the position of the target.


<blockquote style="background-color:ivory">
  <h4>ðŸ‘“ Observation Space  </h4>
  <p>The observation space is 26 dimesion vector whose elemetns are robots velocity (3), acceleration (3), angles (9), angular velocity (3) , target information (4) and the next target information (4).</p>
</blockquote>


### 3. Method 
**Tracking LRP scores while training** : 
Firstly, we trained the model $\pi(a|s;\theta)$ for `1M` samples and stored the model parameters. 
We collected `10` random state samples from the environment. We computed normalized LRP scores of the model to gaurentee that $\sum_p R_p = 1$. It is necessary for the fair comparison between LRP scores. We used `z_plus` rule to compute the relevance scores. 


### 4. Results

Figure 1 shows the Rosbot gazebo simulator. Figure 2 shows the mean LRP scores of 10 states plotted over training time. The relevance score of target position is the highest among other input features and rosbot acceleartion for $x$ direction is the next highest information. **Relevanve score of rosbot feature increased while training, while other features had no visible variance.**  We do not present the reward graph, but it was increasing trend either. 


<center>
<div class="row mt-3">
        <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/exp8/rosbot_env.png" class="img-fluid rounded z-depth-1" zoomable=false %}
            <p style="color:black"> Figure 1. Rosbot Gazebo Simulation. There are two goal points </p>
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/exp8/rosbot_relevance.png" class="img-fluid rounded z-depth-1" zoomable=false %}
            <p style="color:black"> Figure 2. Relevance scores are training for observation of size (26) </p>
    </div>

</div>
</center>

Figure 3 present the relevance scores at reaching the target position over training time. At the beginning of training, relevance scores distributed almost uniformly which is the consistant result with [exp2](http://fxnnxc.github.io/blog/2022/exp_2/). Before reaching the target, the relevance score was distributed for all target information and later focused only on the relative distance information. After reaching the first target, the new target information was added to the current target information position and shows again the distributed relevance scores. 




<center>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/exp8/rosbot_relevance_1.png" class="img-fluid rounded z-depth-1" zoomable=false %}
            <p style="color:black"> Figure 3. Relevance scores while training when reaching the target position.  </p>
    </div>
</div>
</center>


### 5.Conclusion

Verifying the contribution of input features is important for efficiency and interpretability of the model. In this experiment, we present the dynamics of relevance score in the robot domain. The relevance score of input features has high correlation with the human intuition. In addition, there was visible dynamics for robot acceleration feature. 