---
layout: post
title: 'ðŸ•¸ #14 Make a graph from data and cluster it by Markov'
date: 2022-05-16 00:00:00 
description: Discussion about making a grpah from data and how to cluster them.
tags: Cluster, Data
categories: Cluster
---

## 1. Introduction 

Data is vectors and lied on a space. Two data points are similar if they are close enough. Not all data points are connected, but some nearest points are. One way of understanding the data structure is graph representaion. The Graph is composed of nodes and edges. Nodes are aleady given by data points and we have to make edges from the data points. However, deciding whethere two nodes are connected or not is ambiguous. The fully connected graph is one possible solution, but it doesn't give us any insights about the data structure. There are generally three ways to make a graph : 
*k-nearest neighborhood*, *mutual k-nearest neighborhood*, and *epsilon* methods. You can read [the post](https://fxnnxc.github.io/knowledge/kn3-spectral-cluster/) for further information. These methods are highly sensitive to hyperparamters such as the number of neighbors and the epsilon. In this experiment, we show the impact of difference hyperparatmers. 


## 2. Experiments

Here we present two experiments. 

1. **Data to Graph**
2. **Markov Clustering for Graph**

###  ðŸ§ª Data to Graph

We make random data from sklearn datasets.

```python
# hyperparamters
K = [2,5,10,15]
EPS = [0.4, 0.3, 0.2, 0.1]

# generate datasets
generate_gaussian(n_samples=80, n_features=2, n_clusters=15, cluster_std=1.5)
generate_moons(n_samples=80, std=0.1)
```

<center>

<div class="row mt-3">
        <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/exp14/gauss_dataset.png" class="img-fluid rounded z-depth-1" zoomable= true %}
        </div>
        <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/exp14/moon_dataset.png" class="img-fluid rounded z-depth-1" zoomable= true %}
        </div>
    
</div>
<p> Figure 1. Graph representation with each hyperparamters</p> 
</center>

In the comparison of *k-nearest neighbor* and *mutual k-nearest neighbor*,  *k-nearest neighbor* has more edges because of *and* operation, while *mutual* has *or* operation. When hyperparameters are appropriately chosen, the visible clusters are generally acceptable. In the case of *epsilon*, controlling appropriate epsilon scale was hard. On the other hand, selecting the number of neighbor was relatively easy. We hypothesize that the epsilon should be chosen by considering `[min, max, std, n_samples]`.


### ðŸ§ª Markov Clustering 


In the purpose of clustering, we can use similarity matrix. One way of making clusters is [**Markov Clustering**](https://fxnnxc.github.io/knowledge/kn6-markov-clustering/) which is simple but powerful method to cluster arbitrary data distribution.  The basic idea is to consider a weighted adjacency matrix as transition probability. The Markov Clustering consists of two operations, (1) expansion and (2) inflation. Here are codes to generate Markov Clustering

```python
(X,y) = generate_gaussian(n_samples=1000, n_features=2, n_clusters=15, cluster_std=1.0)
sim = make_similarity_matrix(X)
W, edge_matrix = make_weighted_adjacency_matrix(sim, method="k_nearest", n_neighbors=5)
clusters = markov_clustering(W, power=2, r=2, iteration=10)
```

The Figure 2 shows the result of Markov clustering with randomly generated 1000 samples. There were clusters which are automatically made by the algorithm. Even though the number of clusters is not controllable, the dummy data points are well clustered.  


<div class="row mt-3">
<center>
        <div class="col-sm-9 mt-3 mt-md-0">
        {% include figure.html path="assets/img/exp14/markov_clustering.png" class="img-fluid rounded z-depth-1" zoomable= true %}
    </div>
    <p> Figure 2. The result of Markov Clustering </p>
    </center>
</div>

The Figure 3 shows the heatmap of Markov Matrix. The matrix was very sparse and this property makes the values to be clustered. Here we only present Markov matrix for 100 samples. You can see that most values are close to zero. 


<div class="row mt-3">
<center>
        <div class="col-sm-9 mt-3 mt-md-0">
        {% include figure.html path="assets/img/exp14/markov_matrix.png" class="img-fluid rounded z-depth-1" zoomable= true %}
    </div>
    <p> Figure 3. The final markov matrix </p>
    </center>
</div>


## Discussion

* Limitaion : After applying iteartion for markov clustering, it was hard to choose the exampler of each data point. We used argmax to find the exampler.
* Future Research : I'm curious whether it is possible to control the number of clusteres in Markov Clustering!