---
layout: post
title: 'ðŸŒ†#59 SmoothGrad Has Better Kendallâ€™s Rank for Removed Pixels'
date: 2022-12-06 00:00:00
description: discussions about continuous control models
tags: rl
categories: rl
---

# Abstract

Evaluating the input attributions of Deep Neural Network (DNN) is crucial for explanation of a black-box model. Recent work shows that the Integrated Gradients shows positive correlation for Kendall's rank correlation and cosine similarity with the perturbed input. However, input perturbation is a unclear baseline for the deviation of input. For example, SmoothGrad has already considers the input perturbation in its computation. To proper measure of input attribution, we propose masking based input deviation. We show that SmoothGrad and LRP has positive correlation with masked input, while IG fails to construct the strictly positive correlation. 

# Introduction 

Recently, [Want et al.](https://arxiv.org/abs/2205.07279) shows that IG has positive relationship between Kendall's rank correlation and cosine similarity with the perturbed input data. However, it is unclear whether perturbation based deviation is a good choice. Even though the largely perturbed input has larger distance with the original input, the semantic distance could be lower when the perturbed pixel has small importance. For the better deviation of the input, we propose input importance based deviation for the similarity measure. We show that perturbation based input deviation has positive correlation for all input attribution methods, while the importance based perturbation has clear difference for SmoothGrad and IG. 

# Method 

## Kendall's Rank Correlation

Kendall's Rank Correlation measures rank correlation of two ordered sequences. Given $\{(x_1, y_1), \cdots (x_n, y_n) \}$, two pairs $(x_i, y_i)$ and $(x_j, y_j)$ are \textit{concordant} if the order $(x_i, x_j)$ and $(y_i, y_j)$ agrees and discordant if the order disagrees. The Kendall's $\tau$ is defined by 

$$
\begin{align}
    \Large{\tau} & \Large{= \frac{(\# concordant) - (\# discordant)}{(\# pairs)}} \\
    &\Large{=  \frac{2}{n(n-1)} \sum_{i<j} \text{sign}(x_i - x_j) \text{sign} (y_i - y_j) }
\end{align}
$$

When two sequences perfectly agree, $\tau=1$. In the case of perfect disagreement, $\tau=-1$ and independent sequences have $\tau=0$. Kendall's rank correlation is particularly useful for sequences where the magnitude is less important and the order matters. Consider the input attribution of deep neural network such as Integrated Gradient, SmoothGrad, and LRP. These attributions may have different meaning for the quantity. However, two pixels have clear meaning; larger value has higher importance. Therefore, Rank correlation is good for correlation meausre of input attributions. 



## Attribution Methods

**Integrated gradients** (IG) [Sundararajan et al.](https://arxiv.org/abs/1703.01365) computes the attribution with line integral of gradients from a baseline $\mathbf{a}$ to image 
$\mathbf{x}$

$$
\begin{equation}
    \Large{g(x)_i = (x_i - a_i) \times \int_{0}^{1} \frac{f_y(\mathbf{a} + \alpha (\mathbf{x} - \mathbf{a}))}{\partial x_i} d\alpha}
\end{equation}
$$

IG satisfies the axiom of completeness which guarantees $\sum_i g(\mathbf{x})_i = f_y(\mathbf{x}) - f_y(\mathbf{a}))$. As ususal, we use zero as the baseline, \textit{i.e}., $\mathbf{a} = \mathbf{0}$..

**SmoothGrad** [Smilkov et al.](https://arxiv.org/abs/1706.03825) computes the sensitivity with the noised inputs

$$
\begin{equation}
    \Large{\hat{M}_c(x) = \frac{1}{n} \sum_{1}^n M_c (x + \mathcal{N}(0, \sigma^2))}
\end{equation}
$$

where $M_c(x) = \partial f_y(x) / \partial x$ is sensitivity. It is known that $10\% - 20\%$ noise balance the sharpness of sensitivity map and maintain the structure of the original image. Unlike IG, SmoothGrad uses the noise to the input when computing the input attribution. 

**Layer-wise Relevance Propagation** (LRP) measures the contribution of individual pixels. The relavance score of $j$-th neuron in layer $l$ from the layer $l+1$ is computed by 

$$
\begin{equation}
    \Large{R_j^{(l)} = \sum_{k} \frac{ w_{jk} a_j}{\sum_{i}  w_{ik} a_i} R_k^{(l+1)}}
\end{equation}
$$

where $R_j^{(l)}$ represents the relevance score of $j-th$ neuron of layer $l$ with weight  $w_{ij}$, and activation $a_j$. LRP holds the conservative law in the propagation. 


# Experiments


In the original experiment, the original input $\mathbf{x}$ is compared with the perturbed input $\hat{\mathbf{x}} = \mathbf{x} + \epsilon$. We reproduced result for 50 samples in CIFAR 10 dataset with trained 3 blocks CNN model.  Only IG shows almost $\tau=1$. However, the similarity with the input should consider the deviation from the input. One possible deviation is pixel removed image 

$$
\begin{equation}
    \Large{\mathbf{x} = M_{\mathbf{x}} \odot \mathbf{x} }
\end{equation}
$$


where $M_{\mathbf{x}}$ is the masking of the important regions obtained by the attribution map of the original input $\mathbf{x}$. Figure below shows the comparison of methods for different deviation methods of inputs. Pannel (a) shows that the input perturbation deviation shows positive correlation for all input attribution methods. IG shows the most positive correlation. However, it shows that the perturbation of the input has higher effects for IG while LRP and SmoothGrad preserves the attribution even though the input is slightly perturbed. Pannel (b) shows that IG fails to construct the linear correlation for removed portion ratio. That is, the IG do not preserves the linear relationship for the input deviation. SmoothGrad has $\tau=1$ while the IG fails to show the less correlation for cosine similarity and Kendall's rank. 

<center>
<div class="row mt-3">
        {% include figure.html path="assets/img/exp59/method_comparison.png" class="img-fluid-100 rounded z-depth-2 max-width-3" zoomable=true %}
</div>
<p> (a) Correlation and similarity for perturbed input $\hat{\mathbf{x}} = \mathbf{x} + \epsilon$ and original input $x$. IG shows clear correlation. (b) Correlation and similarity for perturbed input $\hat{\mathbf{x}} = M_{\mathbf{x}} \odot \mathbf{x} $ and original input $x$. SmoothGrad shows clear correlation. </p>
</center>



Figure below shows distributions for each $\epsilon$. When the masking ratio is smaller than $0.5$, there is huge difference, while the masking ratio with larger than $0.6$ results in similar results as the important samples are mostly removed. 
 

<center>
<div class="row mt-3">
        {% include figure.html path="assets/img/exp59/remove_portion.png" class="img-fluid-100 rounded z-depth-2 max-width-3" zoomable=true %}
</div>
<div class="row mt-3">
        {% include figure.html path="assets/img/exp59/eps_perturb.png" class="img-fluid-100 rounded z-depth-2 max-width-3" zoomable=true %}
</div>
<p> Scatter plot for each $\epsilon$</p>
</center>


# Conclusion 

 Evaluating the input attribution methods should be done with careful understanding of the explanation bias. In this work, we show that masked inputs have positive correlation for the cosine similarity and the Kendall's rank correlation which demonstrate that simple perturbation of input is not enough deviation of the original input. 

