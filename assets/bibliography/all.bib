

# Watermark
@article{fernandez2023stable,
  title={The stable signature: Rooting watermarks in latent diffusion models},
  author={Fernandez, Pierre and Couairon, Guillaume and J{\'e}gou, Herv{\'e} and Douze, Matthijs and Furon, Teddy},
  journal={arXiv preprint arXiv:2303.15435},
  year={2023}
}

# Watermark
@article{wen2023tree,
  title={Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust},
  author={Wen, Yuxin and Kirchenbauer, John and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2305.20030},
  year={2023}
}


# BERT 
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}


# GPT3
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

# WebGPT
@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

# LoRA
@inproceedings{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

# Clip-Dissect
@inproceedings{oikarinen2022clip,
  title={CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks},
  author={Oikarinen, Tuomas and Weng, Tsui-Wei},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

# Parameter Efficient
@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

# Thread:Circuits
@article{cammarata2020thread,
  author = {Cammarata, Nick and Carter, Shan and Goh, Gabriel and Olah, Chris and Petrov, Michael and Schubert, Ludwig and Voss, Chelsea and Egan, Ben and Lim, Swee Kiat},
  title = {Thread: Circuits},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits},
  doi = {10.23915/distill.00024}
}

# Curve Circuits
@article{cammarata2021curve,
  author = {Cammarata, Nick and Goh, Gabriel and Carter, Shan and Voss, Chelsea and Schubert, Ludwig and Olah, Chris},
  title = {Curve Circuits},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/2020/circuits/curve-circuits},
  doi = {10.23915/distill.00024.006}
}

# Branch Specialization
@article{voss2021branch,
  author = {Voss, Chelsea and Goh, Gabriel and Cammarata, Nick and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
  title = {Branch Specialization},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/2020/circuits/branch-specialization},
  doi = {10.23915/distill.00024.008}
}

# MADDPG, MARL
@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

# LToS, MARL 
@article{yi2022learning,
  title={Learning to Share in Networked Multi-Agent Reinforcement Learning},
  author={Yi, Yuxuan and Li, Ge and Wang, Yaowei and Lu, Zongqing},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15119--15131},
  year={2022}
}

# IPPO, MARL
@article{de2020independent,
  title={Is independent learning all you need in the starcraft multi-agent challenge?},
  author={de Witt, Christian Schroeder and Gupta, Tarun and Makoviichuk, Denys and Makoviychuk, Viktor and Torr, Philip HS and Sun, Mingfei and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2011.09533},
  year={2020}
}

# MAPPO, MARL 
@article{yu2022surprising,
  title={The surprising effectiveness of ppo in cooperative multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24611--24624},
  year={2022}
} 

# TarMAC, MARL 
@inproceedings{das2019tarmac,
  title={Tarmac: Targeted multi-agent communication},
  author={Das, Abhishek and Gervet, Th{\'e}ophile and Romoff, Joshua and Batra, Dhruv and Parikh, Devi and Rabbat, Mike and Pineau, Joelle},
  booktitle={International Conference on Machine Learning},
  pages={1538--1546},
  year={2019},
  organization={PMLR}
}

# QMIX, MARL 
@inproceedings{rashid2018qmix,
  title={QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={4295--4304},
  year={2018},
  organization={PMLR}
}


# Mate, MARL
@inproceedings{pan2022mate,
  title     = {{MATE}: Benchmarking Multi-Agent Reinforcement Learning in Distributed Target Coverage Control},
  author    = {Xuehai Pan and Mickel Liu and Fangwei Zhong and Yaodong Yang and Song-Chun Zhu and Yizhou Wang},
  booktitle = {Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year      = {2022},
  url       = {https://openreview.net/forum?id=SyoUVEyzJbE}
}

# I2C, MARL 
@article{ding2020learning,
  title={Learning individually inferred communication for multi-agent cooperation},
  author={Ding, Ziluo and Huang, Tiejun and Lu, Zongqing},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={22069--22079},
  year={2020}
}


# N2G , Mechanistic Interpretability
@article{foote2023n2g,
  title={N2G: A Scalable Approach for Quantifying Interpretable Neuron Representations in Large Language Models},
  author={Foote, Alex and Nanda, Neel and Kran, Esben and Konstas, Ionnis and Barez, Fazl},
  journal={arXiv preprint arXiv:2304.12918},
  year={2023}
}


# Toy Model, Mechanistic Interpretability
@article{chughtai2023toy,
  title={A toy model of universality: Reverse engineering how networks learn group operations},
  author={Chughtai, Bilal and Chan, Lawrence and Nanda, Neel},
  journal={arXiv preprint arXiv:2302.03025},
  year={2023}
}

# Circuits, Mechanistic Interpretability
@article{olah2020zoom,
  title={Zoom in: An introduction to circuits},
  author={Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  journal={Distill},
  volume={5},
  number={3},
  pages={e00024--001},
  year={2020}
}

# Circuits, Mechanistic Interpretability
@article{cammarata2021curve,
  author = {Cammarata, Nick and Goh, Gabriel and Carter, Shan and Voss, Chelsea and Schubert, Ludwig and Olah, Chris},
  title = {Curve Circuits},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/2020/circuits/curve-circuits},
  doi = {10.23915/distill.00024.006}
}

# Transformer, Automata
@inproceedings{liu2022transformers,
  title={Transformers Learn Shortcuts to Automata},
  author={Liu, Bingbin and Ash, Jordan T and Goel, Surbhi and Krishnamurthy, Akshay and Zhang, Cyril},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}


# Chess, Mechanistic Interpretability 
@article{mcgrath2022acquisition,
  title={Acquisition of chess knowledge in alphazero},
  author={McGrath, Thomas and Kapishnikov, Andrei and Toma{\v{s}}ev, Nenad and Pearce, Adam and Wattenberg, Martin and Hassabis, Demis and Kim, Been and Paquet, Ulrich and Kramnik, Vladimir},
  journal={Proceedings of the National Academy of Sciences},
  volume={119},
  number={47},
  pages={e2206625119},
  year={2022},
  publisher={National Acad Sciences}
}


## World Representationn, Othello, Mechanistic Interpretability 
@inproceedings{li2022emergent,
  title={Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task},
  author={Li, Kenneth and Hopkins, Aspen K and Bau, David and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}


## diffusion, Concept
@article{patel2023conceptbed,
  title={ConceptBed: Evaluating Concept Learning Abilities of Text-to-Image Diffusion Models},
  author={Patel, Maitreya and Gokhale, Tejas and Baral, Chitta and Yang, Yezhou},
  journal={arXiv preprint arXiv:2306.04695},
  year={2023}
}


# Editing 
@inproceedings{bau2020rewriting,
  title={Rewriting a deep generative model},
  author={Bau, David and Liu, Steven and Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part I 16},
  pages={351--369},
  year={2020},
  organization={Springer}
}


@article{santurkar2021editing,
  title={Editing a classifier by rewriting its prediction rules},
  author={Santurkar, Shibani and Tsipras, Dimitris and Elango, Mahalaxmi and Bau, David and Torralba, Antonio and Madry, Aleksander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23359--23373},
  year={2021}
}

## Factual GPT, Interpretability
@article{meng2022locating,
  title={Locating and editing factual associations in GPT},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}

@article{gandikota2023unified,
  title={Unified Concept Editing in Diffusion Models},
  author={Gandikota, Rohit and Orgad, Hadas and Belinkov, Yonatan and Materzy{\'n}ska, Joanna and Bau, David},
  journal={arXiv preprint arXiv:2308.14761},
  year={2023}
}

## OpenAI GPT Interpretability
@article{leike2023language,
  title={Language models can explain neurons in language models},
  author={Jan, Leike and Jeffrey, Wu and Steven, Bills and William, Saunders and Leo, Gao and Henk, Tillman and Daniel, Mossing},
  year={2022},
  journal={OpenAI},
}

## Activation Atlas, Interpretability
@article{carter2019activation,
  author = {Carter, Shan and Armstrong, Zan and Schubert, Ludwig and Johnson, Ian and Olah, Chris},
  title = {Activation Atlas},
  journal = {Distill},
  year = {2019},
  note = {https://distill.pub/2019/activation-atlas},
  doi = {10.23915/distill.00015}
}

## Circuits Thread, Interpretability
@article{schubert2021high-low,
  author = {Schubert, Ludwig and Voss, Chelsea and Cammarata, Nick and Goh, Gabriel and Olah, Chris},
  title = {High-Low Frequency Detectors},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/2020/circuits/frequency-edges},
  doi = {10.23915/distill.00024.005}
}

## Circuits zoom in , Interpretability
@article{olah2020zoom,
  author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  title = {Zoom In: An Introduction to Circuits},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits/zoom-in},
  doi = {10.23915/distill.00024.001}
}

## t-SNE, Interpretability
@article{wattenberg2016how,
  author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
  title = {How to Use t-SNE Effectively},
  journal = {Distill},
  year = {2016},
  url = {http://distill.pub/2016/misread-tsne},
  doi = {10.23915/distill.00002}
}

# Building Blocks, Interpretability 
@article{olah2018the,
  author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
  title = {The Building Blocks of Interpretability},
  journal = {Distill},
  year = {2018},
  note = {https://distill.pub/2018/building-blocks},
  doi = {10.23915/distill.00010}
}

# deep dream, Interpretability 
@misc{mordvintsev2015inceptionism,
  author = {Alexander, Mordvintsev and Christopher, Olah and Mike, Tyka},
  title = {Inceptionism: Going Deeper into Neural Networks},
  year = {2016},
  url = {https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html},
}

# hinton, Interpretability
@article{hinton2022forward,
  title={The forward-forward algorithm: Some preliminary investigations},
  author={Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2212.13345},
  year={2022}
}

# GPT4 
@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

# Neural Turing Machine
@misc{graves2014neural,
      title={Neural Turing Machines}, 
      author={Alex Graves and Greg Wayne and Ivo Danihelka},
      year={2014},
      eprint={1410.5401},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

# Blind, ICLR, RL
@article{wijmans2023emergence,
  title={Emergence of maps in the memories of blind navigation agents},
  author={Wijmans, Erik and Savva, Manolis and Essa, Irfan and Lee, Stefan and Morcos, Ari S and Batra, Dhruv},
  journal={arXiv preprint arXiv:2301.13261},
  year={2023}
}


# Checkerboard Artifact, CNN
@article{odena2016deconvolution,
  author = {Odena, Augustus and Dumoulin, Vincent and Olah, Chris},
  title = {Deconvolution and Checkerboard Artifacts},
  journal = {Distill},
  year = {2016},
  url = {http://distill.pub/2016/deconv-checkerboard},
  doi = {10.23915/distill.00003}
}


# Grokking 
@misc{nanda2023progress,
      title={Progress measures for grokking via mechanistic interpretability}, 
      author={Neel Nanda and Lawrence Chan and Tom Lieberum and Jess Smith and Jacob Steinhardt},
      year={2023},
      eprint={2301.05217},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


# Transformer Interpretability
@article{elhage2021mathematical,
   title={A Mathematical Framework for Transformer Circuits},
   author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2021},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2021/framework/index.html}
}


# LSTM 
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

# GRU
@misc{chung2014empirical,
      title={Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}, 
      author={Junyoung Chung and Caglar Gulcehre and KyungHyun Cho and Yoshua Bengio},
      year={2014},
      eprint={1412.3555},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

# CLIP
@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

# DPO
@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

# Dormant Neuron, Interpretability 
@article{sokar2023dormant,
  title={The dormant neuron phenomenon in deep reinforcement learning},
  author={Sokar, Ghada and Agarwal, Rishabh and Castro, Pablo Samuel and Evci, Utku},
  journal={arXiv preprint arXiv:2302.12902},
  year={2023}
}


# Representation Learning in RL, Domain Adaptation, LUSR 
@misc{xing2021domain,
      title={Domain Adaptation In Reinforcement Learning Via Latent Unified State Representation}, 
      author={Jinwei Xing and Takashi Nagata and Kexin Chen and Xinyun Zou and Emre Neftci and Jeffrey L. Krichmar},
      year={2021},
      eprint={2102.05714},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

# Generative Agents, Multiagent
@inproceedings{Park2023GenerativeAgents,  
author = {Park, Joon Sung and O'Brien, Joseph C. and Cai, Carrie J. and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},  
title = {Generative Agents: Interactive Simulacra of Human Behavior},  
year = {2023},  
publisher = {Association for Computing Machinery},  
address = {New York, NY, USA},  
booktitle = {In the 36th Annual ACM Symposium on User Interface Software and Technology (UIST '23)},  
keywords = {Human-AI interaction, agents, generative AI, large language models},  
location = {San Francisco, CA, USA},  
series = {UIST '23}
}

# StyleDrop, Vision 
@article{sohn2023styledrop,
  title={StyleDrop: Text-to-Image Generation in Any Style},
  author={Sohn, Kihyuk and Ruiz, Nataniel and Lee, Kimin and Chin, Daniel Castro and Blok, Irina and Chang, Huiwen and Barber, Jarred and Jiang, Lu and Entis, Glenn and Li, Yuanzhen and others},
  journal={arXiv preprint arXiv:2306.00983},
  year={2023}
}

# alphafold
@article{jumper2021highly,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
}


@misc{shoker2023confidencebuilding,
      title={Confidence-Building Measures for Artificial Intelligence: Workshop Proceedings}, 
      author={Sarah Shoker and Andrew Reddie and Sarah Barrington and Ruby Booth and Miles Brundage and Husanjot Chahal and Michael Depp and Bill Drexel and Ritwik Gupta and Marina Favaro and Jake Hecla and Alan Hickey and Margarita Konaev and Kirthi Kumar and Nathan Lambert and Andrew Lohn and Cullen O'Keefe and Nazneen Rajani and Michael Sellitto and Robert Trager and Leah Walker and Alexa Wehsener and Jessica Young},
      year={2023},
      eprint={2308.00862},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}


@misc{chu2023protect,
      title={How to Protect Copyright Data in Optimization of Large Language Models?}, 
      author={Timothy Chu and Zhao Song and Chiwun Yang},
      year={2023},
      eprint={2308.12247},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{jiang2023evading,
      title={Evading Watermark based Detection of AI-Generated Content}, 
      author={Zhengyuan Jiang and Jinghuai Zhang and Neil Zhenqiang Gong},
      year={2023},
      eprint={2305.03807},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@article{hisamoto2020membership,
  title={Membership inference attacks on sequence-to-sequence models: Is my data in your machine translation system?},
  author={Hisamoto, Sorami and Post, Matt and Duh, Kevin},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={49--63},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}


@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}


@article{liu2023watermarking,
  title={Watermarking Text Data on Large Language Models for Dataset Copyright Protection},
  author={Liu, Yixin and Hu, Hongsheng and Zhang, Xuyun and Sun, Lichao},
  journal={arXiv preprint arXiv:2305.13257},
  year={2023}
}

@inproceedings{yoo2023robust,
  title={Robust multi-bit natural language watermarking through invariant features},
  author={Yoo, KiYoon and Ahn, Wonhyuk and Jang, Jiho and Kwak, Nojun},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2092--2115},
  year={2023}
}

@article{yu2023codeipprompt,
  title={CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models},
  author={Yu, Zhiyuan and Wu, Yuhao and Zhang, Ning and Wang, Chenguang and Vorobeychik, Yevgeniy and Xiao, Chaowei},
  year={2023}
}

@article{kirchenbauer2023watermark,
  title={A watermark for large language models},
  author={Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom},
  journal={arXiv preprint arXiv:2301.10226},
  year={2023}
}


@article{jiang2023evading,
  title={Evading Watermark based Detection of AI-Generated Content},
  author={Jiang, Zhengyuan and Zhang, Jinghuai and Gong, Neil Zhenqiang},
  journal={arXiv preprint arXiv:2305.03807},
  year={2023}
}

@article{shoker2023confidence,
  title={Confidence-Building Measures for Artificial Intelligence: Workshop Proceedings},
  author={Shoker, Sarah and Reddie, Andrew and Barrington, Sarah and Brundage, Miles and Chahal, Husanjot and Depp, Michael and Drexel, Bill and Gupta, Ritwik and Favaro, Marina and Hecla, Jake and others},
  journal={arXiv preprint arXiv:2308.00862},
  year={2023}
}

@article{chu2023protect,
  title={How to Protect Copyright Data in Optimization of Large Language Models?},
  author={Chu, Timothy and Song, Zhao and Yang, Chiwun},
  journal={arXiv preprint arXiv:2308.12247},
  year={2023}
}

@inproceedings{abdelnabi2021adversarial,
  title={Adversarial watermarking transformer: Towards tracing text provenance with data hiding},
  author={Abdelnabi, Sahar and Fritz, Mario},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  pages={121--140},
  year={2021},
  organization={IEEE}
}

@inproceedings{yang2022tracing,
  title={Tracing text provenance via context-aware lexical substitution},
  author={Yang, Xi and Zhang, Jie and Chen, Kejiang and Zhang, Weiming and Ma, Zehua and Wang, Feng and Yu, Nenghai},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={11613--11621},
  year={2022}
}

@inproceedings{wang2020score,
  title={Score-CAM: Score-weighted visual explanations for convolutional neural networks},
  author={Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={24--25},
  year={2020}
}

@inproceedings{ramaswamy2020ablation,
  title={Ablation-cam: Visual explanations for deep convolutional network via gradient-free localization},
  author={Ramaswamy, Harish Guruprasad and others},
  booktitle={proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={983--991},
  year={2020}
}

@article{bach2015pixel,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015},
  publisher={Public Library of Science}
}

@article{achtibat2022towards,
  title={From" where" to" what": Towards human-understandable explanations through concept relevance propagation},
  author={Achtibat, Reduan and Dreyer, Maximilian and Eisenbraun, Ilona and Bosse, Sebastian and Wiegand, Thomas and Samek, Wojciech and Lapuschkin, Sebastian},
  journal={arXiv preprint arXiv:2206.03208},
  year={2022}
}

@article{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International conference on machine learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}

@article{smilkov2017smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
}