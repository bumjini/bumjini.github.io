---
---

@string{aps = {American Physical Society,}}


@Article{app12010272,
abbr={Allocation. RL.},
AUTHOR = {Park, Bumjin and Kang, Cheongwoong and Choi, Jaesik},
TITLE = {Cooperative Multi-Robot Task Allocation with Reinforcement Learning},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {272},
URL = {https://www.mdpi.com/2076-3417/12/1/272},
HTML = {https://www.mdpi.com/2076-3417/12/1/272},
ISSN = {2076-3417},
ABSTRACT = {This paper deals with the concept of multi-robot task allocation, referring to the assignment of multiple robots to tasks such that an objective function is maximized. The performance of existing meta-heuristic methods worsens as the number of robots or tasks increases. To tackle this problem, a novel Markov decision process formulation for multi-robot task allocation is presented for reinforcement learning. The proposed formulation sequentially allocates robots to tasks to minimize the total time taken to complete them. Additionally, we propose a deep reinforcement learning method to find the best allocation schedule for each problem. Our method adopts the cross-attention mechanism to compute the preference of robots to tasks. The experimental results show that the proposed method finds better solutions than meta-heuristic methods, especially when solving large-scale allocation problems.},
DOI = {10.3390/app12010272},
selected={true}
}

@INPROCEEDINGS{9650047,
abbr={MARL. Patrol.},

  author={Park, Bumjin and Kang, Cheongwoong and Choi, Jaesik},
  booktitle={2021 21st International Conference on Control, Automation and Systems (ICCAS)}, 
  title={Generating Multi-agent Patrol Areas by Reinforcement Learning}, 
  year={2021},
  volume={},
  number={},
  url={https://ieeexplore.ieee.org/abstract/document/9650047},
  html={https://ieeexplore.ieee.org/abstract/document/9650047},
  abstract={In this paper, we designed reinforcement learning environment for distributed patrolling agents. In the partially observable environment, the agents take actions for each one's interest and the non-stationary problem in multi-agent setting encourages the agents not to invade other agent's region. In our environment, the patrolling routes for the agents are generated implicitly. We suggested different types of the environments and evaluated with different initial positions of the agents. We also show how the reinforcement learning algorithm changes the distribution of agents as training time goes.},
  pages={104-107},
  doi={10.23919/ICCAS52745.2021.9650047}}


@Article{s22010150,
abbr={Drone. RL.},
AUTHOR = {Kang, Cheongwoong and Park, Bumjin and Choi, Jaesik},
TITLE = {Scheduling PID Attitude and Position Control Frequencies for Time-Optimal Quadrotor Waypoint Tracking under Unknown External Disturbances},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {150},
url = {https://www.mdpi.com/1424-8220/22/1/150},
html = {https://www.mdpi.com/1424-8220/22/1/150},
PubMedID = {35009692},
ISSN = {1424-8220},
ABSTRACT = {Recently, the use of quadrotors has increased in numerous applications, such as agriculture, rescue, transportation, inspection, and localization. Time-optimal quadrotor waypoint tracking is defined as controlling quadrotors to follow the given waypoints as quickly as possible. Although PID control is widely used for quadrotor control, it is not adaptable to environmental changes, such as various trajectories and dynamic external disturbances. In this work, we discover that adjusting PID control frequencies is necessary for adapting to environmental changes by showing that the optimal control frequencies can be different for different environments. Therefore, we suggest a method to schedule the PID position and attitude control frequencies for time-optimal quadrotor waypoint tracking. The method includes (1) a Control Frequency Agent (CFA) that finds the best control frequencies in various environments, (2) a Quadrotor Future Predictor (QFP) that predicts the next state of a quadrotor, and (3) combining the CFA and QFP for time-optimal quadrotor waypoint tracking under unknown external disturbances. The experimental results prove the effectiveness of the proposed method by showing that it reduces the travel time of a quadrotor for waypoint tracking.},
DOI = {10.3390/s22010150}
}





