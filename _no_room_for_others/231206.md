---
layout: distill
title:   ' 231206 🚀' 
date: 2023-12-03
giscus_comments : true
description: 
bibliography: all.bib
authors: 
    - name: Bumjin Park
      affiliations:
        name: KAIST

---


### 임베딩 방향 벡터 활용하기 

### LoRA 를 활용하기 

### External Memory 활용하기 

외부 메모리를 바탕으로 값을 가져와서 사용하는 방식. 
출처에 해당하는 정보들을 구분된 Query and Value matrix 로 놓고 가져와서 사용하는 방식.

----

## 암기 

Transformer 모델이 외부 데이터를 암기하는 현상은 두드러진다. 이를 더욱 효율적으로 만들고, 암기 능력을 높이는 대표적인 방법은 외부메모리를 활용하는 것이다. 외부 메모리에 대해서 유사도를 바탕으로 접근하면 값을 가져와 사용한다. 이는 query 와 key 부분이 잘 매칭이 되는, 혹은 읽을 수 있는 정보가 있을 경우 값을 가져올 수 있다. 따라서 구조적으로는 Transformer 의 autoregressive 를 활용하면서 키를 넣어서, 그 key 가 외부 메모리에 대한 접근 권한, 접근 여부를 주고, Value 를 가져오는 방식이다. 
Transformer 구조적으로 문장을 해석하는 부분과 새로운 정보를 가져오는 부분이 나눠져 있다면, 새로운 정보를 가져오는 부분에 대해서 특정 암호화된 정보를 명시적으로 넣어줘야 값을 가져올 수 있는 메모리 암호형 트랜스포머이다. 
물론 모델이 암호를 선택하는 부분도 학습을 통해서 진행되지만, 이렇게 명시적으로 나눠져 있다면 두 가지 장점이 있다. 
1) AI 모델이 어떤 출처의 데이터를 사용했는지 확인할 수 있다. 
2) 사용자가 명시적으로 key 를 넣어줄 수 있다
따라서 정보 보호를 보장하는 트랜스포머 구조이다. 

외부 정보를 넣는 또 다른 방법은 MLP matrix를 low-rank 로 업데이트하여 예측하는 것이다. MLP 자체를 업데이트 하기 때문에 언제 넣고 빼는지를 결정해야 한다. 


## 외부 데이터 추출 

[1] 번 연구는 토큰 앞 부분에 prefix 를 두면 새로운 테스크에 대해서 빠르게 적응한다는 점을 보여줬다. 
[2] 번 연구는 학습 데이터에 얼마나 많은 부분을 모델이 암기하는지 연구하였다. 
[3] 번 연구는 외부 데이터로부터 얻은 정보를 logit을 업데이트 하는데 사용하였다. 확률값을 선형보간하여 얻는다. 
[4] 번 연구는 더 많은 데이터, 암기를 위해서 위부 메모리를 사용하는 방법이다. 더 적은 학습 시간으로 더 많은 wikipage 를 암기했다. 
[5] 번 연구는 Prompt 를 만들기 위한 프레임워크를 제안했다. 이는 빈칸에 대한 예측력을 높이기 위해서 추가적인 정보를 더할 필요가 있기 때문이다. 


## Retrieval-Augmented Generation (RAG)

RAG is a paradigm that combines the best of both worlds: the powerful generative capabilities of models like GPT4 and the retrieval capabilities of information database. 

1. Retrieval Phase : given a query, the model searches a large database to find relevant documents or snippets
2. Generation Phase: The model uses the retrieved information to generate a response, ensuring the quality of the output. (The results are used as part of the prompt for Chat GPT to output. )

generation phase is done with BART (encoder and decoder architecture.)
Utilizing the DPR (dense passage retrieval), 
$$
p((y_i|x, z, y_{1:i-1}))
$$

명시적인 텍스트를 추춣해서 값으로 넣어줘야 한다. 이 때, 넣는 모델도 NLP 모델이기에 자연어 형태의 입력을 받을 수 있다. 
Q. autoregression 에서 GPT 모델의 입력값에 대해서 추출된 문서의 일부분을 값으로 넣는 것은 가능한가? 해당 부분은 어떻게 고를 수 있는가? 

----

[1] Prefix Tuning: Optimizing Continuous Prompt for Generation
[2] Quantifying memorization across neural language models
[3] Training Language Models with Memory Augmentation (logit level)
[4] Memorizing Transformers (internal level)
[5] Repository-Level Prompt Generation for Large Language Models of Code 